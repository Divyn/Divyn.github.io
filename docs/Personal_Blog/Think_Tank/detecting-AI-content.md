---
layout: default
title: Weighing in on AI Content Detection Tools - sorry, I don't believe them
parent: Think Tank
---

I was recently caught up in a scenario where people used **AI detectors** to prove the content was not human-written. _Could it be true? Maybe, maybe not._ Here's my 2 cents.

To test this randomly, I took two **Forbes** articles from different sections, _will not disclose them._ One of them **flagged for AI** and the other **flagged as human**, though both have _similar writing style_, same quotes `""` used everywhere as a storyteller.

![](/img/forbes1.png)  
![](/img/forbes2.png)

**My big conclusion: IT CAN BE GAMED, IT CAN BE WRONG**

Oh, I forgot, most of them have a minimum word requirement, try posting different sections of the same content, and you will see different results.

If these tools are taken as **source of truth**, they will **harm lives**. They're not meant to be used as **absolute proof** of low-effort content.

Instead if something _sounds and reads low-effort_, you can use it to confirm. _(even that I won't suggest)_

We're at a stage where AI content writing tools have grown a steep curve while the detection tools have not caught up.

> Will the gap widen from here? Yes.

Then what is the solution? Read, read, read! Read the material, does it have good, factual information? Is it useful, does it do what it was intended to do? If so, why go down the rabbit hole "was it/ was it, not AI". I am not saying ends justify means, I am saying we're not good enough to figure it out easily, it is a long-winded road.
